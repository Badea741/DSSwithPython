{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Unit 9 Lecture 1 - Artificial Intelligence: Supervised Learning\n",
    "\n",
    "ESI4628: Decision Support Systems for Industrial Engineers<br>\n",
    "University of Central Florida\n",
    "Dr. Ivan Garibay, Ramya Akula, Mostafa Saeidi, Madeline Schiappa, and Brett Belcher. \n",
    "https://github.com/igaribay/DSSwithPython/blob/master/DSS-Week09/Notebook/DSS-Unit09-Lecture01.2018.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Notebook Learning Objectives\n",
    "After studying this notebook students should be able to:\n",
    "- Undertand basic concepts on artificial intelligence and machine learning\n",
    "- Develop supervised learning models using Scikit-Learn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Overview\n",
    "\n",
    "Artificial intelligence (AI) is making its way into all industries. Companies that are not already exploiting the benefits of the \"AI revolution\" are frantically upgrading their business models to remain competitive. No doubt artificial intelligence is here to stay. The US government and private sector are investing heavily to remain the world leader on this crucial field.\n",
    "\n",
    "The AI that is currently used in industry, it is based on statistical methods and artificial intelligence algorithms developed on the 70's and 80's. It is just now that those technologies have come to age, in part, thanks to the availability of large amounts of data and the unprecedented, inexpensive and readily available computational power. Of course, algorithms have continually become more efficient and powerful. An example of these advances **deep learning**. Deep learning have brought orders of magnitude improvement in accuracy compared with traditional learning algorithms. For more information about deep learning see <a href=\"https://arxiv.org/pdf/1404.7828.pdf\">reference 1</a> and for a Python library for deep learning see <a href=\"https://pytorch.org\">reference 2</a>. Current AI research focus on going beyond statistical learning and partner recognition (where deep learning is the reigning king) into the more challenging problems of infusing AI  with _common-sense reasoning_, with the ability to explain its actions or decisions, so called _explainability_, and in general, making AIs become better _human partners_. For an example of this **third wave of AI** please see <a href=\"https://www.youtube.com/watch?time_continue=2564&v=7ROelYvo8f0\">reference 4</a>.\n",
    "\n",
    "This class have provided you with the programming, data, and statistical foundations needed to understand a particular type of artificial intelligence: machine learning. Machine learning comes in two main flavors: \n",
    "- supervised learning\n",
    "- unsupervised learning\n",
    "\n",
    "A supervised learning algorithm work by learning by example and with a \"supervisor\" that tell the algorithm when it got it right and when it made a mistake. After the supervisor \"trains\" the algorithm using many examples (training data set), then the algorithm is presented with a never seen before example (test data set) in order to test if the algorithm was able to \"learn\" from the training data.\n",
    "\n",
    "We will use the Python library **Scikit-Learn** (see <a href=\"http://scikit-learn.org/stable/index.html\">reference 3</a>). This library is a comprehensive and state-of-the-art collection of machine learning algorithms ready to use.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Introduction to Supervised Learning through Scikit-Learn\n",
    "\n",
    "## What is scikit-learn?\n",
    "Scikit is a machine learning python library built off of packages you have recently been introduced to such as numpy, scipy and matplotlib. For more information, visit the <a href='http://scikit-learn.org/stable/index.html#'>scikit-learn homepage</a>\n",
    "\n",
    "The library contains function in the following machine learning categories:\n",
    "- <a href='http://scikit-learn.org/stable/supervised_learning.html#supervised-learning'> Classification</a> \n",
    "- <a href='http://scikit-learn.org/stable/supervised_learning.html#supervised-learning'> Regression </a> \n",
    "- <a href='http://scikit-learn.org/stable/modules/clustering.html#clustering'> Clustering </a> \n",
    "- <a href='http://scikit-learn.org/stable/modules/decomposition.html#decompositions'>Dimensionality Reduction</a>\n",
    "- <a href='http://scikit-learn.org/stable/model_selection.html#model-selection'>Model Selection</a> \n",
    "- <a href='http://scikit-learn.org/stable/modules/preprocessing.html#preprocessing'>Preprocessing </a> \n",
    "\n",
    "Scikit-learn should be installed along with your Anaconda3 installation. However, if this is not the case, follow the installation instructions provided by scikit-learn <a href='http://scikit-learn.org/stable/install.html'>here</a>\n",
    "\n",
    "Next, lets import some of the packages we will use and see what version you are running!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The scikit-learn version is 0.19.1.\n",
      "The pandas version is 0.23.0\n",
      "The matplotlib version is 2.2.2\n",
      "The numpy version is 1.14.3\n"
     ]
    }
   ],
   "source": [
    "import sklearn\n",
    "print('The scikit-learn version is {}.'.format(sklearn.__version__))\n",
    "import pandas as pd\n",
    "print('The pandas version is {}'.format(pd.__version__))\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "print('The matplotlib version is {}'.format(matplotlib.__version__))\n",
    "import numpy as np\n",
    "print('The numpy version is {}'.format(np.__version__))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What is supervised learning?\n",
    "\n",
    "Supervised learning are algorithms that learn patterns from a data. They are trained useing a subset of the data. This data is labeled. A labeled dataset represents a set of problems for which we know the answers. Supervised learning alrorithms aim to generalize their learning in order to be able to acurately provide an answer to all possible inputs, in particular inputs that are not part of their training dataset. \n",
    "\n",
    "Examples of techniques in supervised learning:</p> \n",
    "<li style=\"font-size: 16px\"><a href='http://scikit-learn.org/stable/modules/linear_model.html#logistic-regression'>logistic regression</a></li>\n",
    "<li style=\"font-size: 16px\"><a href='http://scikit-learn.org/stable/modules/svm.html'>support vector machines</a></li>\n",
    "<li style=\"font-size: 16px\"><a href='http://scikit-learn.org/stable/modules/tree.html'>decision trees</a></li>\n",
    "<li style=\"font-size: 16px\"><a href='http://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html'>random forest</a></li>\n",
    "\n",
    "\n",
    "## The classification problem\n",
    "\n",
    "We will focus on classification tasks in this notebook. **Classification** is the prediction of discrete variables i.e. YES/NO. Formally, classification is the problem of finding: \n",
    "\n",
    "$$h(\\mathbf{x}): \\mathbb{R^d}\\to\\mathbb{K}$$\n",
    "\n",
    "that maps an input space in $\\mathbb{R^d}$ onto a discrete set of $k$ target outputs or classes $\\mathbb{K}=\\{1,...,k\\}$. In this setting, the **features** are arranged into a vector $\\mathbf{x}$ or $d$ real-valued numbers.\n",
    "\n",
    "\n",
    "## Scikit-learn input\n",
    "\n",
    "A problem in Scikit-learn is defined as follows:\n",
    "\n",
    "### 1. Input data is an array of the size $[n_{samples}, n_{features}]$ and a vector of the size $n_{samples}$\n",
    "\n",
    "The input dataset for any Sklearn learning algorithm consist on a matrix of size $[n_{samples}, n_{features}]$ that we will call the <code>feature matrix</code>, and a vector of size $n_{samples}$ that we will call the <code>label vector</code>.\n",
    "#### Feature Matrix\n",
    "\n",
    "- $n_{samples}$: it is the number of samples $n$. Each sample is an item to process (in our case to classify). A sample could be a picture, a documents, a file, a row in a database, etc. This is the data that you will use to train your algorithm. In machine learning, samples are also refer to as: instances or examples.\n",
    "\n",
    "- $n_{features}$: it is the number of features $d$. A feature is a distinct characteristic of an item that can be used to quantitatively described the item. For an item related to \"a person applying for a loan\", posible features could be \"credit score\", \"age\", \"load amount requested\", \"salary\", etc. The features that you select are very importnatn for the performance of your algorithm. In machine learning, features are also refer to as: attributes, dimensions, regressors, covariates, predictors, or independent variables.\n",
    "\n",
    "$$n_{samples}=n$$\n",
    "$$n_{features}=d$$\n",
    "$$\\text{Feature matrix    :    } \n",
    "\\mathbf{X} = \n",
    "\\begin{pmatrix} \n",
    "x_{11} & x_{12} & \\cdots & x_{1d} \\\\ \n",
    "x_{21} & x_{22} & \\cdots & x_{2d} \\\\\n",
    "x_{31} & x_{32} & \\cdots & x_{3d} \\\\\n",
    "\\vdots & \\vdots & \\ddots & \\vdots \\\\\n",
    "\\vdots & \\vdots & \\ddots & \\vdots \\\\\n",
    "x_{n1} & x_{n2} & \\cdots & x_{nd} \n",
    "\\end{pmatrix}\n",
    "$$\n",
    "\n",
    "#### Label vector\n",
    "\n",
    "- The label vector contains the answers or solutions to the samples. \n",
    "For classification, it contains the correct class for each of the $n$ samples. In machine learning, the label vector is also known as: outcome, response, or dependent variable.\n",
    "\n",
    "$$\n",
    "\\text{Label vector: }\n",
    "\\mathbf{y^T} = [y_1, y_2, y_3,\\cdots, y_n]\n",
    "$$\n",
    "### 2. Scikit-learn interfaces\n",
    "- <code>fit()</code>: interface for building and fitting models\n",
    "- <code>predict()</code>: interface for making predictions\n",
    "- <code>transform()</code>: interface for converting data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lending Club Example\n",
    "This dataset is provided by the Lending Club, a peer-to-peer lending company offering loans funded by other people acting as hub connection borrowers and investors. The potential investors assesses the risk of clients applying for a loan of a certain amount and offer to fund a portion of the loan. If enough investors offer to fund the loan, then the loan is successful and the client can receive the money they asked for, or at least an amount close the complete loan.\n",
    "\n",
    "A **failed loan** occurs when the investors (<code>funded_amnt_inv</code>) do not provided funds to cover at least %5 of the requested loan amount (<code>loan_amnt</code>). \n",
    "\n",
    "> The task is to predict if a loan application will fail to be funded or not\n",
    "\n",
    "We define the finary classification task as the problem of sucesfully predict when a loan will fail. The **failed loans** are defined as: \n",
    "\n",
    "$$\\frac{loan-funded}{loan}\\geq0.95$$ \n",
    "\n",
    "Lending Club **loan data** and **declined loan data**, as well as a complete data dictionary can be downloaded <a href='https://www.lendingclub.com/info/download-data.action'> here for years 2007-2018</a>. Relevant data columns and their description follow:\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table>\n",
    "    <tr>\n",
    "        <th>Column</th>\n",
    "        <th>Description</th>\n",
    "    </tr>\n",
    "   <tr>\n",
    "        <td>annual_inc</td>\n",
    "        <td>The annual income provided by the borrower during registration.</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>delinq_2yrs</td>\n",
    "        <td> The number of 30+ days past-due incidences of delinquency in the borrower's credit file for the past 2 years\n",
    "</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>dti</td>\n",
    "        <td> A ratio calculated using the borrower’s total monthly debt payments on the total debt obligations, excluding mortgage and the requested LC loan, divided by the borrower’s self-reported monthly income.\n",
    "</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>earliest_cr_line</td>\n",
    "        <td> The month the borrower's earliest reported credit line was opened\n",
    "</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>emp_length</td>\n",
    "        <td> Employment length in years. Possible values are between 0 and 10 where 0 means less than one year and 10 means ten or more years.\n",
    "</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>home_ownership</td>\n",
    "        <td> The home ownership status provided by the borrower during registration. Our values are: RENT, OWN, MORTGAGE, OTHER.\n",
    "</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>installment</td>\n",
    "        <td> The monthly payment owed by the borrower if the loan originates.\n",
    "</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>int_rate</td>\n",
    "        <td> Interest Rate on the loan\n",
    "</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>is_inc_v</td>\n",
    "        <td> Indicates if income was verified by LC, not verified, or if the income source was verified\n",
    "</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>last_fico_range_high</td>\n",
    "        <td> The last upper boundary of range the borrower’s FICO belongs to pulled.\n",
    "</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>last_fico_range_low</td>\n",
    "        <td> The last lower boundary of range the borrower’s FICO belongs to pulled.\n",
    "</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>fico_range_high</td>\n",
    "        <td> The upper boundary of range the borrower’s FICO belongs to.\n",
    "</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>fico_range_low</td>\n",
    "        <td> The lower boundary of range the borrower’s FICO belongs to.\n",
    "</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>mths_since_last_delinq</td>\n",
    "        <td> The number of months since the borrower's last delinquency.\n",
    "</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>mths_since_last_major_derog</td>\n",
    "        <td> Months since most recent 90-day or worse rating\n",
    "</td>\n",
    "    </tr>\n",
    "     <tr>\n",
    "        <td>open_acc</td>\n",
    "        <td> The number of open credit lines in the borrower's credit file.\n",
    "</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>term</td>\n",
    "        <td> The number of payments on the loan. Values are in months and can be either 36 or 60.\n",
    "</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>total_acc</td>\n",
    "        <td> The total number of credit lines currently in the borrower's credit file\n",
    "</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>loan_amnt</td>\n",
    "        <td> The listed amount of the loan applied for by the borrower. If at some point in time, the credit department reduces the loan amount, then it will be reflected in this value.</td>\n",
    "    </tr>\n",
    "\n",
    "\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 1: Loading, transforming and understanding the data\n",
    "Now, lets read the data into a dataframe <code>df_lend</code> by using <code>pd.read_csv</code> to read the raw data from <code>LoanStats3a.csv</code>, a file downloaded from https://www.lendingclub.com/info/download-data.action. Then lets **select** only 13 columns as **features** from the original 145 columns in the raw data, we select the features that we think are more relevant for our classification problem. The result is our **feature matrix**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(42538, 145)\n",
      "(42538, 13)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>loan_amnt</th>\n",
       "      <th>funded_amnt</th>\n",
       "      <th>funded_amnt_inv</th>\n",
       "      <th>term</th>\n",
       "      <th>int_rate</th>\n",
       "      <th>installment</th>\n",
       "      <th>emp_length</th>\n",
       "      <th>home_ownership</th>\n",
       "      <th>annual_inc</th>\n",
       "      <th>dti</th>\n",
       "      <th>delinq_2yrs</th>\n",
       "      <th>mths_since_last_delinq</th>\n",
       "      <th>total_acc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5000.0</td>\n",
       "      <td>5000.0</td>\n",
       "      <td>4975.0</td>\n",
       "      <td>36 months</td>\n",
       "      <td>10.65%</td>\n",
       "      <td>162.87</td>\n",
       "      <td>10+ years</td>\n",
       "      <td>RENT</td>\n",
       "      <td>24000.0</td>\n",
       "      <td>27.65</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2500.0</td>\n",
       "      <td>2500.0</td>\n",
       "      <td>2500.0</td>\n",
       "      <td>60 months</td>\n",
       "      <td>15.27%</td>\n",
       "      <td>59.83</td>\n",
       "      <td>&lt; 1 year</td>\n",
       "      <td>RENT</td>\n",
       "      <td>30000.0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2400.0</td>\n",
       "      <td>2400.0</td>\n",
       "      <td>2400.0</td>\n",
       "      <td>36 months</td>\n",
       "      <td>15.96%</td>\n",
       "      <td>84.33</td>\n",
       "      <td>10+ years</td>\n",
       "      <td>RENT</td>\n",
       "      <td>12252.0</td>\n",
       "      <td>8.72</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10000.0</td>\n",
       "      <td>10000.0</td>\n",
       "      <td>10000.0</td>\n",
       "      <td>36 months</td>\n",
       "      <td>13.49%</td>\n",
       "      <td>339.31</td>\n",
       "      <td>10+ years</td>\n",
       "      <td>RENT</td>\n",
       "      <td>49200.0</td>\n",
       "      <td>20.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>37.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3000.0</td>\n",
       "      <td>3000.0</td>\n",
       "      <td>3000.0</td>\n",
       "      <td>60 months</td>\n",
       "      <td>12.69%</td>\n",
       "      <td>67.79</td>\n",
       "      <td>1 year</td>\n",
       "      <td>RENT</td>\n",
       "      <td>80000.0</td>\n",
       "      <td>17.94</td>\n",
       "      <td>0.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>38.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   loan_amnt  funded_amnt  funded_amnt_inv        term int_rate  installment  \\\n",
       "0     5000.0       5000.0           4975.0   36 months   10.65%       162.87   \n",
       "1     2500.0       2500.0           2500.0   60 months   15.27%        59.83   \n",
       "2     2400.0       2400.0           2400.0   36 months   15.96%        84.33   \n",
       "3    10000.0      10000.0          10000.0   36 months   13.49%       339.31   \n",
       "4     3000.0       3000.0           3000.0   60 months   12.69%        67.79   \n",
       "\n",
       "  emp_length home_ownership  annual_inc    dti  delinq_2yrs  \\\n",
       "0  10+ years           RENT     24000.0  27.65          0.0   \n",
       "1   < 1 year           RENT     30000.0   1.00          0.0   \n",
       "2  10+ years           RENT     12252.0   8.72          0.0   \n",
       "3  10+ years           RENT     49200.0  20.00          0.0   \n",
       "4     1 year           RENT     80000.0  17.94          0.0   \n",
       "\n",
       "   mths_since_last_delinq  total_acc  \n",
       "0                     NaN        9.0  \n",
       "1                     NaN        4.0  \n",
       "2                     NaN       10.0  \n",
       "3                    35.0       37.0  \n",
       "4                    38.0       38.0  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_lend = pd.read_csv('../Data/LoanStats3a.csv', skiprows=1, low_memory=False)\n",
    "print df_lend.shape\n",
    "\n",
    "keep_cols = ['loan_amnt', 'funded_amnt', 'funded_amnt_inv', 'term', 'int_rate', 'installment', 'emp_length', 'home_ownership', 'annual_inc', 'dti', 'delinq_2yrs', 'mths_since_last_delinq', 'total_acc']\n",
    "df_lend = df_lend[keep_cols]\n",
    "print df_lend.shape\n",
    "df_lend.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we will add an extra column in our dataset <code>df_lend</code> to be our **label vector**. Using the logic described earlier we compute **failed loans** as follows: \n",
    "\n",
    "$$\n",
    "\\text{failed loans} = \n",
    "\\begin{cases}\n",
    "  -1 \\Leftrightarrow \\frac{loan-funded}{loan}\\geq0.95\\\\    \n",
    "  +1         \\quad\\quad \\text{otherwise}\n",
    "\\end{cases}\n",
    "$$\n",
    "\n",
    "then, we store the resulting values of the calculation above into the extra column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Examples of Failed Loans\n",
      "42533    1\n",
      "42534   -1\n",
      "42535   -1\n",
      "42536    1\n",
      "42537    1\n",
      "Name: failed_loan, dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>loan_amnt</th>\n",
       "      <th>funded_amnt</th>\n",
       "      <th>funded_amnt_inv</th>\n",
       "      <th>term</th>\n",
       "      <th>int_rate</th>\n",
       "      <th>installment</th>\n",
       "      <th>emp_length</th>\n",
       "      <th>home_ownership</th>\n",
       "      <th>annual_inc</th>\n",
       "      <th>dti</th>\n",
       "      <th>delinq_2yrs</th>\n",
       "      <th>mths_since_last_delinq</th>\n",
       "      <th>total_acc</th>\n",
       "      <th>targets</th>\n",
       "      <th>failed_loan</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>42533</th>\n",
       "      <td>2525.0</td>\n",
       "      <td>2525.0</td>\n",
       "      <td>225.0</td>\n",
       "      <td>36 months</td>\n",
       "      <td>9.33%</td>\n",
       "      <td>80.69</td>\n",
       "      <td>&lt; 1 year</td>\n",
       "      <td>RENT</td>\n",
       "      <td>110000.0</td>\n",
       "      <td>10.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.910891</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42534</th>\n",
       "      <td>6500.0</td>\n",
       "      <td>6500.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>36 months</td>\n",
       "      <td>8.38%</td>\n",
       "      <td>204.84</td>\n",
       "      <td>&lt; 1 year</td>\n",
       "      <td>NONE</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42535</th>\n",
       "      <td>5000.0</td>\n",
       "      <td>5000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>36 months</td>\n",
       "      <td>7.75%</td>\n",
       "      <td>156.11</td>\n",
       "      <td>10+ years</td>\n",
       "      <td>MORTGAGE</td>\n",
       "      <td>70000.0</td>\n",
       "      <td>8.81</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42536</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42537</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       loan_amnt  funded_amnt  funded_amnt_inv        term int_rate  \\\n",
       "42533     2525.0       2525.0            225.0   36 months    9.33%   \n",
       "42534     6500.0       6500.0              0.0   36 months    8.38%   \n",
       "42535     5000.0       5000.0              0.0   36 months    7.75%   \n",
       "42536        NaN          NaN              NaN         NaN      NaN   \n",
       "42537        NaN          NaN              NaN         NaN      NaN   \n",
       "\n",
       "       installment emp_length home_ownership  annual_inc    dti  delinq_2yrs  \\\n",
       "42533        80.69   < 1 year           RENT    110000.0  10.00          NaN   \n",
       "42534       204.84   < 1 year           NONE         NaN   4.00          NaN   \n",
       "42535       156.11  10+ years       MORTGAGE     70000.0   8.81          NaN   \n",
       "42536          NaN        NaN            NaN         NaN    NaN          NaN   \n",
       "42537          NaN        NaN            NaN         NaN    NaN          NaN   \n",
       "\n",
       "       mths_since_last_delinq  total_acc   targets  failed_loan  \n",
       "42533                     NaN        NaN  0.910891            1  \n",
       "42534                     NaN        NaN  1.000000           -1  \n",
       "42535                     NaN        NaN  1.000000           -1  \n",
       "42536                     NaN        NaN       NaN            1  \n",
       "42537                     NaN        NaN       NaN            1  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loan = df_lend['loan_amnt'].values\n",
    "funded = df_lend['funded_amnt_inv'].values\n",
    "targets = np.abs(loan-funded)/loan\n",
    "\n",
    "df_lend['targets'] = targets\n",
    "y = [-1 if t >= .95 else 1 for t in targets]\n",
    "df_lend['failed_loan'] = y\n",
    "df_lend['failed_loan'].value_counts()\n",
    "print \"Examples of Failed Loans\"\n",
    "print df_lend['failed_loan'].tail() #examples of failed loans from data\n",
    "df_lend.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets visualize the data, failed and succesful loans:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "labels = 'Succesful loan', 'Failed loan'\n",
    "sizes = df_lend['failed_loan'].value_counts()\n",
    "sizes = [sizes[1], sizes[-1] ]\n",
    "colors = ['gold', 'black']\n",
    " \n",
    "# Plot\n",
    "plt.pie(sizes, labels=labels, colors=colors,\n",
    "        autopct='%1.1f%%', shadow=True, startangle=140)\n",
    " \n",
    "plot_ = plt.axis('equal')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that there is a significant disporportion of positive labels to negative ones, making the dataset **unbalanced**. This can have drastic consequences for a classifier.\n",
    "\n",
    "We can also plot the histogram of:\n",
    "$$\\frac{loan-funded}{loan}\\geq0.95$$ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.07701981762404166\n",
      "0.1997447197699951\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYcAAAD8CAYAAACcjGjIAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMi4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvhp/UCwAAFN9JREFUeJzt3X+sX/V93/HnKzYk2ZIUEy4Rss3MWlcLQapD7sBTpI1CBoZKMZWSCqQWF6G5YzC1W1SFdNJIIUhkUxoNidCR4mGqNsBoO6zUqWcRoixT+GEaAhiKuAUGtyBwaqBEqGTQ9/74ftx95c/Xvt/7w/f6x/MhHX3PeZ/POd/PB1/7dc85n++XVBWSJA17z1J3QJJ0+DEcJEkdw0GS1DEcJEkdw0GS1DEcJEkdw0GS1JkxHJK8L8lDSX6YZHeS327125M8l+TRtqxr9SS5KclUkseSnDl0rk1JnmnLpqH6J5I83o65KUkOxWAlSeNZPkabt4Fzq+rHSY4DvpfkW23fb1bVPfu1vxBY25azgVuAs5OcCFwLTAIFPJJkW1W91tpsBh4AtgMbgG8hSVoSM4ZDDT5C/eO2eVxbDvax6o3AHe24B5KckOQU4BxgZ1XtBUiyE9iQ5DvAh6rq+61+B3AxM4TDSSedVGvWrJmp+5KkIY888siPqmpipnbjXDmQZBnwCPAzwM1V9WCSK4EbkvxH4D7gmqp6G1gJvDh0+HSrHaw+PaI+qh+bGVxhcOqpp7Jr165xui9JapL8n3HajfVAuqrerap1wCrgrCRnAF8A/gnwT4ETgc/ve+9Rp5hDfVQ/bq2qyaqanJiYMfgkSXM0q9lKVfU68B1gQ1W9XANvA/8NOKs1mwZWDx22CnhphvqqEXVJ0hIZZ7bSRJIT2vr7gU8Bf9GeI9BmFl0MPNEO2QZc1mYtrQfeqKqXgR3A+UlWJFkBnA/saPveTLK+nesy4N6FHaYkaTbGeeZwCrC1PXd4D3B3VX0zybeTTDC4LfQo8K9b++3ARcAU8BZwOUBV7U1yPfBwa3fdvofTwJXA7cD7GTyIdqaSJC2hHKn/P4fJycnygbQkzU6SR6pqcqZ2fkJaktQxHCRJHcNBktQxHCRJnbE+IX20WXPNn47V7vkbf+EQ90SSDk9eOUiSOoaDJKljOEiSOoaDJKljOEiSOoaDJKljOEiSOoaDJKljOEiSOoaDJKljOEiSOoaDJKljOEiSOoaDJKljOEiSOoaDJKljOEiSOjOGQ5L3JXkoyQ+T7E7y261+WpIHkzyT5K4kx7f6e9v2VNu/ZuhcX2j1p5NcMFTf0GpTSa5Z+GFKkmZjnCuHt4Fzq+rngHXAhiTrgS8DX62qtcBrwBWt/RXAa1X1M8BXWzuSnA5cAnwM2AB8LcmyJMuAm4ELgdOBS1tbSdISmTEcauDHbfO4thRwLnBPq28FLm7rG9s2bf95SdLqd1bV21X1HDAFnNWWqap6tqp+AtzZ2kqSlshYzxzab/iPAq8CO4G/BF6vqndak2lgZVtfCbwI0Pa/AXx4uL7fMQeqj+rH5iS7kuzas2fPOF2XJM3BWOFQVe9W1TpgFYPf9D86qll7zQH2zbY+qh+3VtVkVU1OTEzM3HFJ0pzMarZSVb0OfAdYD5yQZHnbtQp4qa1PA6sB2v6fAvYO1/c75kB1SdISGWe20kSSE9r6+4FPAU8B9wOfac02Afe29W1tm7b/21VVrX5Jm810GrAWeAh4GFjbZj8dz+Ch9baFGJwkaW6Wz9yEU4CtbVbRe4C7q+qbSZ4E7kzyJeAHwG2t/W3A7yeZYnDFcAlAVe1OcjfwJPAOcFVVvQuQ5GpgB7AM2FJVuxdshJKkWZsxHKrqMeDjI+rPMnj+sH/9b4HPHuBcNwA3jKhvB7aP0V9J0iLwE9KSpI7hIEnqGA6SpI7hIEnqGA6SpI7hIEnqGA6SpI7hIEnqGA6SpI7hIEnqGA6SpI7hIEnqGA6SpI7hIEnqGA6SpI7hIEnqGA6SpI7hIEnqGA6SpI7hIEnqGA6SpI7hIEnqzBgOSVYnuT/JU0l2J/n1Vv9ikr9K8mhbLho65gtJppI8neSCofqGVptKcs1Q/bQkDyZ5JsldSY5f6IFKksY3zpXDO8DnquqjwHrgqiSnt31frap1bdkO0PZdAnwM2AB8LcmyJMuAm4ELgdOBS4fO8+V2rrXAa8AVCzQ+SdIczBgOVfVyVf15W38TeApYeZBDNgJ3VtXbVfUcMAWc1Zapqnq2qn4C3AlsTBLgXOCedvxW4OK5DkiSNH+zeuaQZA3wceDBVro6yWNJtiRZ0WorgReHDptutQPVPwy8XlXv7Fcf9f6bk+xKsmvPnj2z6bokaRbGDockHwD+CPiNqvob4Bbgp4F1wMvAV/Y1HXF4zaHeF6turarJqpqcmJgYt+uSpFlaPk6jJMcxCIY/qKo/BqiqV4b2fx34ZtucBlYPHb4KeKmtj6r/CDghyfJ29TDcXpK0BMaZrRTgNuCpqvqdofopQ81+EXiirW8DLkny3iSnAWuBh4CHgbVtZtLxDB5ab6uqAu4HPtOO3wTcO79hSZLmY5wrh08CvwI8nuTRVvstBrON1jG4BfQ88GsAVbU7yd3AkwxmOl1VVe8CJLka2AEsA7ZU1e52vs8Ddyb5EvADBmEkSVoiM4ZDVX2P0c8Fth/kmBuAG0bUt486rqqeZTCbSZJ0GPAT0pKkjuEgSeoYDpKkjuEgSeoYDpKkjuEgSeoYDpKkjuEgSeoYDpKkjuEgSeoYDpKkjuEgSeoYDpKkjuEgSeoYDpKkjuEgSeoYDpKkjuEgSeoYDpKkjuEgSeoYDpKkjuEgSerMGA5JVie5P8lTSXYn+fVWPzHJziTPtNcVrZ4kNyWZSvJYkjOHzrWptX8myaah+ieSPN6OuSlJDsVgJUnjGefK4R3gc1X1UWA9cFWS04FrgPuqai1wX9sGuBBY25bNwC0wCBPgWuBs4Czg2n2B0tpsHjpuw/yHJkmaqxnDoaperqo/b+tvAk8BK4GNwNbWbCtwcVvfCNxRAw8AJyQ5BbgA2FlVe6vqNWAnsKHt+1BVfb+qCrhj6FySpCUwq2cOSdYAHwceBD5SVS/DIECAk1uzlcCLQ4dNt9rB6tMj6qPef3OSXUl27dmzZzZdlyTNwtjhkOQDwB8Bv1FVf3OwpiNqNYd6X6y6taomq2pyYmJipi5LkuZorHBIchyDYPiDqvrjVn6l3RKivb7a6tPA6qHDVwEvzVBfNaIuSVoi48xWCnAb8FRV/c7Qrm3AvhlHm4B7h+qXtVlL64E32m2nHcD5SVa0B9HnAzvavjeTrG/vddnQuSRJS2D5GG0+CfwK8HiSR1vtt4AbgbuTXAG8AHy27dsOXARMAW8BlwNU1d4k1wMPt3bXVdXetn4lcDvwfuBbbZEkLZEZw6Gqvsfo5wIA541oX8BVBzjXFmDLiPou4IyZ+iJJWhx+QlqS1DEcJEkdw0GS1DEcJEkdw0GS1DEcJEkdw0GS1DEcJEkdw0GS1DEcJEkdw0GS1DEcJEkdw0GS1DEcJEkdw0GS1DEcJEkdw0GS1DEcJEkdw0GS1DEcJEkdw0GS1JkxHJJsSfJqkieGal9M8ldJHm3LRUP7vpBkKsnTSS4Yqm9otakk1wzVT0vyYJJnktyV5PiFHKAkafbGuXK4Hdgwov7VqlrXlu0ASU4HLgE+1o75WpJlSZYBNwMXAqcDl7a2AF9u51oLvAZcMZ8BSZLmb8ZwqKrvAnvHPN9G4M6qeruqngOmgLPaMlVVz1bVT4A7gY1JApwL3NOO3wpcPMsxSJIW2HyeOVyd5LF222lFq60EXhxqM91qB6p/GHi9qt7Zry5JWkJzDYdbgJ8G1gEvA19p9YxoW3Ooj5Rkc5JdSXbt2bNndj2WJI1tTuFQVa9U1btV9XfA1xncNoLBb/6rh5quAl46SP1HwAlJlu9XP9D73lpVk1U1OTExMZeuS5LGMKdwSHLK0OYvAvtmMm0DLkny3iSnAWuBh4CHgbVtZtLxDB5ab6uqAu4HPtOO3wTcO5c+SZIWzvKZGiT5BnAOcFKSaeBa4Jwk6xjcAnoe+DWAqtqd5G7gSeAd4Kqqered52pgB7AM2FJVu9tbfB64M8mXgB8Aty3Y6CRJczJjOFTVpSPKB/wHvKpuAG4YUd8ObB9Rf5b/f1tKknQY8BPSkqSO4SBJ6hgOkqSO4SBJ6hgOkqSO4SBJ6hgOkqSO4SBJ6hgOkqSO4SBJ6hgOkqSO4SBJ6hgOkqSO4SBJ6hgOkqSO4SBJ6hgOkqSO4SBJ6hgOkqSO4SBJ6hgOkqSO4SBJ6swYDkm2JHk1yRNDtROT7EzyTHtd0epJclOSqSSPJTlz6JhNrf0zSTYN1T+R5PF2zE1JstCDlCTNzjhXDrcDG/arXQPcV1VrgfvaNsCFwNq2bAZugUGYANcCZwNnAdfuC5TWZvPQcfu/lyRpkc0YDlX1XWDvfuWNwNa2vhW4eKh+Rw08AJyQ5BTgAmBnVe2tqteAncCGtu9DVfX9qirgjqFzSZKWyFyfOXykql4GaK8nt/pK4MWhdtOtdrD69Ii6JGkJLfQD6VHPC2oO9dEnTzYn2ZVk1549e+bYRUnSTOYaDq+0W0K011dbfRpYPdRuFfDSDPVVI+ojVdWtVTVZVZMTExNz7LokaSZzDYdtwL4ZR5uAe4fql7VZS+uBN9ptpx3A+UlWtAfR5wM72r43k6xvs5QuGzqXJGmJLJ+pQZJvAOcAJyWZZjDr6Ebg7iRXAC8An23NtwMXAVPAW8DlAFW1N8n1wMOt3XVVte8h95UMZkS9H/hWWyRJS2jGcKiqSw+w67wRbQu46gDn2QJsGVHfBZwxUz8kSYvHT0hLkjqGgySpYzhIkjqGgySpYzhIkjqGgySpYzhIkjqGgySpYzhIkjqGgySpYzhIkjqGgySpYzhIkjqGgySpYzhIkjqGgySpYzhIkjqGgySpYzhIkjqGgySpYzhIkjqGgySpM69wSPJ8kseTPJpkV6udmGRnkmfa64pWT5KbkkwleSzJmUPn2dTaP5Nk0/yGJEmar4W4cvj5qlpXVZNt+xrgvqpaC9zXtgEuBNa2ZTNwCwzCBLgWOBs4C7h2X6BIkpbGobittBHY2ta3AhcP1e+ogQeAE5KcAlwA7KyqvVX1GrAT2HAI+iVJGtN8w6GA/5nkkSSbW+0jVfUyQHs9udVXAi8OHTvdageqS5KWyPJ5Hv/JqnopycnAziR/cZC2GVGrg9T7EwwCaDPAqaeeOtu+SpLGNK8rh6p6qb2+CvwJg2cGr7TbRbTXV1vzaWD10OGrgJcOUh/1frdW1WRVTU5MTMyn65Kkg5hzOCT5h0k+uG8dOB94AtgG7JtxtAm4t61vAy5rs5bWA2+02047gPOTrGgPos9vNUnSEpnPbaWPAH+SZN95/rCq/izJw8DdSa4AXgA+29pvBy4CpoC3gMsBqmpvkuuBh1u766pq7zz6JUmapzmHQ1U9C/zciPpfA+eNqBdw1QHOtQXYMte+SJIWlp+QliR1DAdJUsdwkCR1DAdJUsdwkCR1DAdJUsdwkCR1DAdJUsdwkCR1DAdJUsdwkCR1DAdJUsdwkCR1DAdJUme+/5vQo9qaa/50rHbP3/gLh7gnkrS4vHKQJHUMB0lSx3CQJHUMB0lSx3CQJHUMB0lSx6msC8Apr5KONodNOCTZAPwXYBnwe1V14xJ3acGNGyJgkEhaWodFOCRZBtwM/EtgGng4ybaqenJpe6bFMpvgHJcBqyPJ4XYH4rAIB+AsYKqqngVIciewEThmw+FQ/GN5rDnc/rLpyODPzcDhEg4rgReHtqeBs5eoLzrGGMSai6P95+ZwCYeMqFXXKNkMbG6bP07y9Bzf7yTgR3M89kjlmI8Nx9qYj7Xxki/Pe8z/aJxGh0s4TAOrh7ZXAS/t36iqbgVune+bJdlVVZPzPc+RxDEfG461MR9r44XFG/Ph8jmHh4G1SU5LcjxwCbBtifskScesw+LKoareSXI1sIPBVNYtVbV7ibslSceswyIcAKpqO7B9kd5u3remjkCO+dhwrI35WBsvLNKYU9U995UkHeMOl2cOkqTDyFEdDkk2JHk6yVSSa0bsf2+Su9r+B5OsWfxeLpwxxvvvkzyZ5LEk9yUZa0rb4WymMQ+1+0ySSnLEz2wZZ8xJfqn9We9O8oeL3ceFNsbP9qlJ7k/yg/bzfdFS9HOhJNmS5NUkTxxgf5Lc1P57PJbkzAXvRFUdlQuDB9t/Cfxj4Hjgh8Dp+7X5N8DvtvVLgLuWut+HeLw/D/yDtn7lkTzeccfc2n0Q+C7wADC51P1ehD/ntcAPgBVt++Sl7vcijPlW4Mq2fjrw/FL3e55j/ufAmcATB9h/EfAtBp8RWw88uNB9OJqvHP7+Kzmq6ifAvq/kGLYR2NrW7wHOSzLqA3lHghnHW1X3V9VbbfMBBp8nOZKN82cMcD3wn4C/XczOHSLjjPlfATdX1WsAVfXqIvdxoY0z5gI+1NZ/ihGfkzqSVNV3gb0HabIRuKMGHgBOSHLKQvbhaA6HUV/JsfJAbarqHeAN4MOL0ruFN854h13B4DePI9mMY07ycWB1VX1zMTt2CI3z5/yzwM8m+d9JHmjfeHwkG2fMXwR+Ock0g1mP/3ZxurZkZvv3fdYOm6msh8A4X8kx1td2HCHGHkuSXwYmgX9xSHt06B10zEneA3wV+NXF6tAiGOfPeTmDW0vnMLg6/F9Jzqiq1w9x3w6VccZ8KXB7VX0lyT8Dfr+N+e8OffeWxCH/t+tovnIY5ys5/r5NkuUMLkcPdil3OBvrK0iSfAr4D8Cnq+rtRerboTLTmD8InAF8J8nzDO7NbjvCH0qP+3N9b1X936p6DniaQVgcqcYZ8xXA3QBV9X3gfQy+d+loNdbf9/k4msNhnK/k2AZsauufAb5d7WnPEWjG8bZbLP+VQTAc6fehYYYxV9UbVXVSVa2pqjUMnrN8uqp2LU13F8Q4P9f/g8HkA5KcxOA207OL2suFNc6YXwDOA0jyUQbhsGdRe7m4tgGXtVlL64E3qurlhXyDo/a2Uh3gKzmSXAfsqqptwG0MLj+nGFwxXLJ0PZ6fMcf7n4EPAP+9PXd/oao+vWSdnqcxx3xUGXPMO4DzkzwJvAv8ZlX99dL1en7GHPPngK8n+XcMbq/86hH8ix5JvsHgtuBJ7TnKtcBxAFX1uwyeq1wETAFvAZcveB+O4P9+kqRD5Gi+rSRJmiPDQZLUMRwkSR3DQZLUMRwkSR3DQZLUMRwkSR3DQZLU+X9hUo3W/SbaGgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "loan = df_lend['loan_amnt'].values\n",
    "funded = df_lend['funded_amnt_inv'].values\n",
    "targets = np.abs(loan-funded)/loan\n",
    "#cleaning data for histo\n",
    "wrk_records = np.where(~np.isnan(targets))\n",
    "targets_clean = targets[wrk_records]\n",
    "#ploting and calculating stats\n",
    "plt.hist(targets_clean,bins=30)\n",
    "print np.mean(targets_clean)\n",
    "print np.std(targets_clean)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We observe that the mean is 0.07 which means that in average loan and funded are really close to each other. This explains why our **failed loan** variable has so few \"-1\" values. As a result, the vast mayority of our data contains succesful loans."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 2: Select your model\n",
    "\n",
    "\n",
    "- We have 42,537 samples that contain 13 features (loan term, interest rate, employment length, annual income, etc)  each: feature matrix\n",
    "- We have calculated the \"ground truth\" for each of these samples: (-1) if the loan failed and (+1) otherwise: label vector.\n",
    "- As a result, our problem is a binary classification task. \n",
    "- There are many algorithms that are designed for classification taks. \n",
    "- We will just start by picking one, later in the course we will see how to select a good one for our problem.\n",
    "\n",
    "A well known clustering algorithm is the k-nearest neighbor algorithm. Below a quick introduction. For more details about this algorithm, see pages 462-470 in Python for Data Science Handbook by Jake VanderPlas.\n",
    "\n",
    "### What is K-Nearest Neighbor?\n",
    "\n",
    "This algorithm, when used for classification, uses the neighboring values of a particular input value to make a prediction. The input is assigned to the class most common among its $k$ nearest neighbors where $k\\in\\mathbf{R}$. The parameter $k$ is defined in the beginning as a hyperparameter, or a configuration that is prior to the model fit and is not estimated from the data but can be tuned to be more beneficial to the fitting of the model on the data. Determining the distance between the input value and other values is commonly done by Euclidean distance for continuous variables or Hamming distance for discrete variables. We will not go into too much detail here, but we will use this algorithm as a starting example on sklearn. For more information on sklearn's package, see the <a href='http://scikit-learn.org/stable/modules/neighbors.html#neighbors'>sklearn.neighbors documentation.</a>\n",
    "\n",
    "One thing to note is this algorithm is computation heavy. This is because it must hold all other values in memory in order to measure the closest $k$ values to the input value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4140, 15)\n",
      "4140\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3600.0</td>\n",
       "      <td>2375.0</td>\n",
       "      <td>76.31</td>\n",
       "      <td>30000.0</td>\n",
       "      <td>15.04</td>\n",
       "      <td>0.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0.0970</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>23000.0</td>\n",
       "      <td>23000.0</td>\n",
       "      <td>767.89</td>\n",
       "      <td>95000.0</td>\n",
       "      <td>16.07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.1236</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7000.0</td>\n",
       "      <td>7000.0</td>\n",
       "      <td>225.84</td>\n",
       "      <td>66000.0</td>\n",
       "      <td>6.58</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0999</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7200.0</td>\n",
       "      <td>7200.0</td>\n",
       "      <td>239.04</td>\n",
       "      <td>64000.0</td>\n",
       "      <td>22.28</td>\n",
       "      <td>0.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>0.1197</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>12000.0</td>\n",
       "      <td>7325.0</td>\n",
       "      <td>225.88</td>\n",
       "      <td>60000.0</td>\n",
       "      <td>24.06</td>\n",
       "      <td>0.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>0.0691</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>7500.0</td>\n",
       "      <td>7500.0</td>\n",
       "      <td>249.00</td>\n",
       "      <td>145000.0</td>\n",
       "      <td>18.16</td>\n",
       "      <td>0.0</td>\n",
       "      <td>53.0</td>\n",
       "      <td>0.1197</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>16000.0</td>\n",
       "      <td>6125.0</td>\n",
       "      <td>215.34</td>\n",
       "      <td>66996.0</td>\n",
       "      <td>16.25</td>\n",
       "      <td>1.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0.1600</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>20000.0</td>\n",
       "      <td>16250.0</td>\n",
       "      <td>532.93</td>\n",
       "      <td>62400.0</td>\n",
       "      <td>20.77</td>\n",
       "      <td>0.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>0.1112</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>15000.0</td>\n",
       "      <td>15000.0</td>\n",
       "      <td>499.73</td>\n",
       "      <td>80600.0</td>\n",
       "      <td>3.48</td>\n",
       "      <td>0.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>0.1221</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>5350.0</td>\n",
       "      <td>5350.0</td>\n",
       "      <td>180.57</td>\n",
       "      <td>4000.0</td>\n",
       "      <td>15.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.1312</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>3500.0</td>\n",
       "      <td>3500.0</td>\n",
       "      <td>116.61</td>\n",
       "      <td>68004.0</td>\n",
       "      <td>17.82</td>\n",
       "      <td>0.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0.1221</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>15800.0</td>\n",
       "      <td>15800.0</td>\n",
       "      <td>341.49</td>\n",
       "      <td>84000.0</td>\n",
       "      <td>6.29</td>\n",
       "      <td>0.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>0.1074</td>\n",
       "      <td>2.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>9000.0</td>\n",
       "      <td>9000.0</td>\n",
       "      <td>308.06</td>\n",
       "      <td>50004.0</td>\n",
       "      <td>8.21</td>\n",
       "      <td>0.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>0.1411</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>7500.0</td>\n",
       "      <td>7500.0</td>\n",
       "      <td>242.04</td>\n",
       "      <td>79000.0</td>\n",
       "      <td>15.21</td>\n",
       "      <td>1.0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>0.1001</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>5000.0</td>\n",
       "      <td>5000.0</td>\n",
       "      <td>160.78</td>\n",
       "      <td>45000.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0976</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>20000.0</td>\n",
       "      <td>20000.0</td>\n",
       "      <td>664.00</td>\n",
       "      <td>90012.0</td>\n",
       "      <td>18.96</td>\n",
       "      <td>0.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>0.1197</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>4800.0</td>\n",
       "      <td>4800.0</td>\n",
       "      <td>149.87</td>\n",
       "      <td>21000.0</td>\n",
       "      <td>6.34</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.0775</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>7000.0</td>\n",
       "      <td>7000.0</td>\n",
       "      <td>242.05</td>\n",
       "      <td>45000.0</td>\n",
       "      <td>19.12</td>\n",
       "      <td>0.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>0.1482</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>3500.0</td>\n",
       "      <td>3500.0</td>\n",
       "      <td>111.82</td>\n",
       "      <td>87000.0</td>\n",
       "      <td>13.50</td>\n",
       "      <td>0.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>0.0932</td>\n",
       "      <td>1.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>7500.0</td>\n",
       "      <td>7500.0</td>\n",
       "      <td>237.21</td>\n",
       "      <td>225000.0</td>\n",
       "      <td>7.44</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.0863</td>\n",
       "      <td>1.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>24000.0</td>\n",
       "      <td>14900.0</td>\n",
       "      <td>487.74</td>\n",
       "      <td>70000.0</td>\n",
       "      <td>25.46</td>\n",
       "      <td>0.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>0.1099</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>21850.0</td>\n",
       "      <td>15175.0</td>\n",
       "      <td>345.21</td>\n",
       "      <td>28800.0</td>\n",
       "      <td>19.21</td>\n",
       "      <td>0.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>0.1299</td>\n",
       "      <td>2.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>18000.0</td>\n",
       "      <td>18000.0</td>\n",
       "      <td>594.25</td>\n",
       "      <td>98000.0</td>\n",
       "      <td>5.08</td>\n",
       "      <td>0.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>0.1158</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>7500.0</td>\n",
       "      <td>7500.0</td>\n",
       "      <td>244.52</td>\n",
       "      <td>79992.0</td>\n",
       "      <td>13.02</td>\n",
       "      <td>0.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>0.1071</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>11600.0</td>\n",
       "      <td>11600.0</td>\n",
       "      <td>402.42</td>\n",
       "      <td>133228.0</td>\n",
       "      <td>16.79</td>\n",
       "      <td>0.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>0.1505</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>1800.0</td>\n",
       "      <td>1600.0</td>\n",
       "      <td>50.38</td>\n",
       "      <td>31000.0</td>\n",
       "      <td>8.50</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0.0832</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>14000.0</td>\n",
       "      <td>14000.0</td>\n",
       "      <td>464.30</td>\n",
       "      <td>84240.0</td>\n",
       "      <td>10.33</td>\n",
       "      <td>0.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>0.1189</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>15000.0</td>\n",
       "      <td>15000.0</td>\n",
       "      <td>491.30</td>\n",
       "      <td>149616.0</td>\n",
       "      <td>9.52</td>\n",
       "      <td>1.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>0.1103</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>10000.0</td>\n",
       "      <td>10000.0</td>\n",
       "      <td>337.52</td>\n",
       "      <td>276000.0</td>\n",
       "      <td>20.06</td>\n",
       "      <td>1.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>0.1312</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>35000.0</td>\n",
       "      <td>21750.0</td>\n",
       "      <td>500.36</td>\n",
       "      <td>149000.0</td>\n",
       "      <td>8.83</td>\n",
       "      <td>0.0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>0.1349</td>\n",
       "      <td>2.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4110</th>\n",
       "      <td>7725.0</td>\n",
       "      <td>7725.0</td>\n",
       "      <td>256.55</td>\n",
       "      <td>105000.0</td>\n",
       "      <td>9.38</td>\n",
       "      <td>5.0</td>\n",
       "      <td>46.0</td>\n",
       "      <td>0.1199</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4111</th>\n",
       "      <td>6300.0</td>\n",
       "      <td>6300.0</td>\n",
       "      <td>217.32</td>\n",
       "      <td>60000.0</td>\n",
       "      <td>3.66</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.1465</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4112</th>\n",
       "      <td>2500.0</td>\n",
       "      <td>2500.0</td>\n",
       "      <td>78.23</td>\n",
       "      <td>36000.0</td>\n",
       "      <td>6.43</td>\n",
       "      <td>1.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>0.0790</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4113</th>\n",
       "      <td>25000.0</td>\n",
       "      <td>25000.0</td>\n",
       "      <td>848.27</td>\n",
       "      <td>73476.0</td>\n",
       "      <td>24.56</td>\n",
       "      <td>1.0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>0.1349</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4114</th>\n",
       "      <td>10750.0</td>\n",
       "      <td>10750.0</td>\n",
       "      <td>365.95</td>\n",
       "      <td>33600.0</td>\n",
       "      <td>21.93</td>\n",
       "      <td>0.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>0.1372</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4115</th>\n",
       "      <td>8000.0</td>\n",
       "      <td>8000.0</td>\n",
       "      <td>263.78</td>\n",
       "      <td>72000.0</td>\n",
       "      <td>20.25</td>\n",
       "      <td>0.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>0.1149</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4116</th>\n",
       "      <td>10500.0</td>\n",
       "      <td>10500.0</td>\n",
       "      <td>326.65</td>\n",
       "      <td>55000.0</td>\n",
       "      <td>11.72</td>\n",
       "      <td>0.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>0.0751</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4117</th>\n",
       "      <td>11000.0</td>\n",
       "      <td>11000.0</td>\n",
       "      <td>254.82</td>\n",
       "      <td>62000.0</td>\n",
       "      <td>12.60</td>\n",
       "      <td>1.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>0.1380</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4118</th>\n",
       "      <td>4800.0</td>\n",
       "      <td>4800.0</td>\n",
       "      <td>150.15</td>\n",
       "      <td>92000.0</td>\n",
       "      <td>12.82</td>\n",
       "      <td>0.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>0.0788</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4119</th>\n",
       "      <td>13200.0</td>\n",
       "      <td>13200.0</td>\n",
       "      <td>416.64</td>\n",
       "      <td>60000.0</td>\n",
       "      <td>28.54</td>\n",
       "      <td>0.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>0.0849</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4120</th>\n",
       "      <td>6000.0</td>\n",
       "      <td>6000.0</td>\n",
       "      <td>210.80</td>\n",
       "      <td>171000.0</td>\n",
       "      <td>8.27</td>\n",
       "      <td>0.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>0.1595</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4121</th>\n",
       "      <td>5600.0</td>\n",
       "      <td>5600.0</td>\n",
       "      <td>142.18</td>\n",
       "      <td>100000.0</td>\n",
       "      <td>9.18</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0.1799</td>\n",
       "      <td>2.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4122</th>\n",
       "      <td>8400.0</td>\n",
       "      <td>8400.0</td>\n",
       "      <td>202.36</td>\n",
       "      <td>48000.0</td>\n",
       "      <td>11.45</td>\n",
       "      <td>0.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>0.1557</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4123</th>\n",
       "      <td>1000.0</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>33.93</td>\n",
       "      <td>16800.0</td>\n",
       "      <td>18.21</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.1348</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4124</th>\n",
       "      <td>7200.0</td>\n",
       "      <td>7200.0</td>\n",
       "      <td>152.95</td>\n",
       "      <td>52000.0</td>\n",
       "      <td>24.14</td>\n",
       "      <td>0.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>0.0999</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4125</th>\n",
       "      <td>2400.0</td>\n",
       "      <td>2400.0</td>\n",
       "      <td>85.36</td>\n",
       "      <td>13000.0</td>\n",
       "      <td>4.89</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.1682</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4126</th>\n",
       "      <td>8500.0</td>\n",
       "      <td>8500.0</td>\n",
       "      <td>193.67</td>\n",
       "      <td>28000.0</td>\n",
       "      <td>23.40</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.1306</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4127</th>\n",
       "      <td>5200.0</td>\n",
       "      <td>5200.0</td>\n",
       "      <td>176.29</td>\n",
       "      <td>52000.0</td>\n",
       "      <td>9.51</td>\n",
       "      <td>0.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>0.1343</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4128</th>\n",
       "      <td>30000.0</td>\n",
       "      <td>30000.0</td>\n",
       "      <td>667.19</td>\n",
       "      <td>180000.0</td>\n",
       "      <td>9.49</td>\n",
       "      <td>0.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0.1199</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4129</th>\n",
       "      <td>8400.0</td>\n",
       "      <td>8400.0</td>\n",
       "      <td>266.89</td>\n",
       "      <td>55000.0</td>\n",
       "      <td>6.52</td>\n",
       "      <td>0.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>0.0894</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4130</th>\n",
       "      <td>4000.0</td>\n",
       "      <td>4000.0</td>\n",
       "      <td>122.40</td>\n",
       "      <td>28000.0</td>\n",
       "      <td>12.81</td>\n",
       "      <td>0.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>0.0639</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4131</th>\n",
       "      <td>6500.0</td>\n",
       "      <td>6500.0</td>\n",
       "      <td>207.46</td>\n",
       "      <td>65004.0</td>\n",
       "      <td>15.49</td>\n",
       "      <td>0.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0.0925</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4132</th>\n",
       "      <td>12000.0</td>\n",
       "      <td>12000.0</td>\n",
       "      <td>386.70</td>\n",
       "      <td>63000.0</td>\n",
       "      <td>16.48</td>\n",
       "      <td>0.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0.0991</td>\n",
       "      <td>1.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4133</th>\n",
       "      <td>25000.0</td>\n",
       "      <td>25000.0</td>\n",
       "      <td>652.51</td>\n",
       "      <td>110000.0</td>\n",
       "      <td>9.27</td>\n",
       "      <td>0.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>0.1929</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4134</th>\n",
       "      <td>6000.0</td>\n",
       "      <td>6000.0</td>\n",
       "      <td>194.31</td>\n",
       "      <td>66500.0</td>\n",
       "      <td>13.62</td>\n",
       "      <td>0.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>0.1025</td>\n",
       "      <td>1.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4135</th>\n",
       "      <td>10000.0</td>\n",
       "      <td>10000.0</td>\n",
       "      <td>366.77</td>\n",
       "      <td>108000.0</td>\n",
       "      <td>23.41</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.1904</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4136</th>\n",
       "      <td>4500.0</td>\n",
       "      <td>4500.0</td>\n",
       "      <td>148.38</td>\n",
       "      <td>24000.0</td>\n",
       "      <td>3.70</td>\n",
       "      <td>1.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.1149</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4137</th>\n",
       "      <td>10000.0</td>\n",
       "      <td>10000.0</td>\n",
       "      <td>311.11</td>\n",
       "      <td>36996.0</td>\n",
       "      <td>5.45</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0.0751</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4138</th>\n",
       "      <td>3500.0</td>\n",
       "      <td>3500.0</td>\n",
       "      <td>119.61</td>\n",
       "      <td>110000.0</td>\n",
       "      <td>15.50</td>\n",
       "      <td>0.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>0.1399</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4139</th>\n",
       "      <td>8325.0</td>\n",
       "      <td>8325.0</td>\n",
       "      <td>282.48</td>\n",
       "      <td>31200.0</td>\n",
       "      <td>23.92</td>\n",
       "      <td>0.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>0.1349</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4140 rows × 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           0        1       2         3      4    5     6       7    8     9   \\\n",
       "0      3600.0   2375.0   76.31   30000.0  15.04  0.0  27.0  0.0970  1.0  10.0   \n",
       "1     23000.0  23000.0  767.89   95000.0  16.07  0.0  20.0  0.1236  1.0   3.0   \n",
       "2      7000.0   7000.0  225.84   66000.0   6.58  0.0   6.0  0.0999  1.0   0.0   \n",
       "3      7200.0   7200.0  239.04   64000.0  22.28  0.0  34.0  0.1197  1.0  10.0   \n",
       "4     12000.0   7325.0  225.88   60000.0  24.06  0.0  38.0  0.0691  1.0   7.0   \n",
       "5      7500.0   7500.0  249.00  145000.0  18.16  0.0  53.0  0.1197  1.0   1.0   \n",
       "6     16000.0   6125.0  215.34   66996.0  16.25  1.0  27.0  0.1600  1.0   0.0   \n",
       "7     20000.0  16250.0  532.93   62400.0  20.77  0.0  18.0  0.1112  1.0  10.0   \n",
       "8     15000.0  15000.0  499.73   80600.0   3.48  0.0  18.0  0.1221  1.0   2.0   \n",
       "9      5350.0   5350.0  180.57    4000.0  15.00  0.0   1.0  0.1312  1.0   1.0   \n",
       "10     3500.0   3500.0  116.61   68004.0  17.82  0.0  35.0  0.1221  1.0  10.0   \n",
       "11    15800.0  15800.0  341.49   84000.0   6.29  0.0  32.0  0.1074  2.0  10.0   \n",
       "12     9000.0   9000.0  308.06   50004.0   8.21  0.0  14.0  0.1411  1.0   3.0   \n",
       "13     7500.0   7500.0  242.04   79000.0  15.21  1.0  42.0  0.1001  1.0  10.0   \n",
       "14     5000.0   5000.0  160.78   45000.0   0.00  0.0   3.0  0.0976  1.0   1.0   \n",
       "15    20000.0  20000.0  664.00   90012.0  18.96  0.0  31.0  0.1197  1.0   1.0   \n",
       "16     4800.0   4800.0  149.87   21000.0   6.34  0.0   8.0  0.0775  1.0   0.0   \n",
       "17     7000.0   7000.0  242.05   45000.0  19.12  0.0  31.0  0.1482  1.0   0.0   \n",
       "18     3500.0   3500.0  111.82   87000.0  13.50  0.0  31.0  0.0932  1.0   9.0   \n",
       "19     7500.0   7500.0  237.21  225000.0   7.44  0.0   9.0  0.0863  1.0   8.0   \n",
       "20    24000.0  14900.0  487.74   70000.0  25.46  0.0  15.0  0.1099  1.0  10.0   \n",
       "21    21850.0  15175.0  345.21   28800.0  19.21  0.0  15.0  0.1299  2.0   7.0   \n",
       "22    18000.0  18000.0  594.25   98000.0   5.08  0.0  40.0  0.1158  1.0   2.0   \n",
       "23     7500.0   7500.0  244.52   79992.0  13.02  0.0  17.0  0.1071  1.0   0.0   \n",
       "24    11600.0  11600.0  402.42  133228.0  16.79  0.0  29.0  0.1505  1.0  10.0   \n",
       "25     1800.0   1600.0   50.38   31000.0   8.50  0.0  11.0  0.0832  1.0   2.0   \n",
       "26    14000.0  14000.0  464.30   84240.0  10.33  0.0  15.0  0.1189  1.0   4.0   \n",
       "27    15000.0  15000.0  491.30  149616.0   9.52  1.0  38.0  0.1103  1.0   0.0   \n",
       "28    10000.0  10000.0  337.52  276000.0  20.06  1.0  44.0  0.1312  1.0   2.0   \n",
       "29    35000.0  21750.0  500.36  149000.0   8.83  0.0  39.0  0.1349  2.0  10.0   \n",
       "...       ...      ...     ...       ...    ...  ...   ...     ...  ...   ...   \n",
       "4110   7725.0   7725.0  256.55  105000.0   9.38  5.0  46.0  0.1199  1.0  10.0   \n",
       "4111   6300.0   6300.0  217.32   60000.0   3.66  0.0  10.0  0.1465  1.0   6.0   \n",
       "4112   2500.0   2500.0   78.23   36000.0   6.43  1.0  16.0  0.0790  1.0   5.0   \n",
       "4113  25000.0  25000.0  848.27   73476.0  24.56  1.0  42.0  0.1349  1.0   5.0   \n",
       "4114  10750.0  10750.0  365.95   33600.0  21.93  0.0  18.0  0.1372  1.0   2.0   \n",
       "4115   8000.0   8000.0  263.78   72000.0  20.25  0.0  22.0  0.1149  1.0  10.0   \n",
       "4116  10500.0  10500.0  326.65   55000.0  11.72  0.0  22.0  0.0751  1.0  10.0   \n",
       "4117  11000.0  11000.0  254.82   62000.0  12.60  1.0  29.0  0.1380  2.0   3.0   \n",
       "4118   4800.0   4800.0  150.15   92000.0  12.82  0.0  17.0  0.0788  1.0   1.0   \n",
       "4119  13200.0  13200.0  416.64   60000.0  28.54  0.0  16.0  0.0849  1.0   0.0   \n",
       "4120   6000.0   6000.0  210.80  171000.0   8.27  0.0  30.0  0.1595  1.0   5.0   \n",
       "4121   5600.0   5600.0  142.18  100000.0   9.18  0.0  11.0  0.1799  2.0  10.0   \n",
       "4122   8400.0   8400.0  202.36   48000.0  11.45  0.0  13.0  0.1557  2.0   1.0   \n",
       "4123   1000.0   1000.0   33.93   16800.0  18.21  0.0   3.0  0.1348  1.0   2.0   \n",
       "4124   7200.0   7200.0  152.95   52000.0  24.14  0.0  28.0  0.0999  2.0   0.0   \n",
       "4125   2400.0   2400.0   85.36   13000.0   4.89  0.0   4.0  0.1682  1.0   0.0   \n",
       "4126   8500.0   8500.0  193.67   28000.0  23.40  0.0  10.0  0.1306  2.0   5.0   \n",
       "4127   5200.0   5200.0  176.29   52000.0   9.51  0.0  18.0  0.1343  1.0   3.0   \n",
       "4128  30000.0  30000.0  667.19  180000.0   9.49  0.0  26.0  0.1199  2.0   1.0   \n",
       "4129   8400.0   8400.0  266.89   55000.0   6.52  0.0  31.0  0.0894  1.0  10.0   \n",
       "4130   4000.0   4000.0  122.40   28000.0  12.81  0.0  24.0  0.0639  1.0   6.0   \n",
       "4131   6500.0   6500.0  207.46   65004.0  15.49  0.0  27.0  0.0925  1.0   6.0   \n",
       "4132  12000.0  12000.0  386.70   63000.0  16.48  0.0  26.0  0.0991  1.0   8.0   \n",
       "4133  25000.0  25000.0  652.51  110000.0   9.27  0.0  19.0  0.1929  2.0   2.0   \n",
       "4134   6000.0   6000.0  194.31   66500.0  13.62  0.0  18.0  0.1025  1.0   8.0   \n",
       "4135  10000.0  10000.0  366.77  108000.0  23.41  1.0  10.0  0.1904  1.0   6.0   \n",
       "4136   4500.0   4500.0  148.38   24000.0   3.70  1.0   8.0  0.1149  1.0   0.0   \n",
       "4137  10000.0  10000.0  311.11   36996.0   5.45  0.0  12.0  0.0751  1.0   5.0   \n",
       "4138   3500.0   3500.0  119.61  110000.0  15.50  0.0  25.0  0.1399  1.0   0.0   \n",
       "4139   8325.0   8325.0  282.48   31200.0  23.92  0.0  24.0  0.1349  1.0   4.0   \n",
       "\n",
       "       10   11   12   13   14  \n",
       "0    -1.0 -1.0 -1.0 -1.0  1.0  \n",
       "1    -1.0 -1.0 -1.0 -1.0  1.0  \n",
       "2    -1.0 -1.0 -1.0 -1.0  1.0  \n",
       "3     1.0 -1.0 -1.0 -1.0 -1.0  \n",
       "4    -1.0 -1.0 -1.0  1.0 -1.0  \n",
       "5     1.0 -1.0 -1.0 -1.0 -1.0  \n",
       "6    -1.0 -1.0 -1.0 -1.0  1.0  \n",
       "7    -1.0 -1.0 -1.0 -1.0  1.0  \n",
       "8     1.0 -1.0 -1.0 -1.0 -1.0  \n",
       "9    -1.0 -1.0 -1.0  1.0 -1.0  \n",
       "10    1.0 -1.0 -1.0 -1.0 -1.0  \n",
       "11    1.0 -1.0 -1.0 -1.0 -1.0  \n",
       "12    1.0 -1.0 -1.0 -1.0 -1.0  \n",
       "13    1.0 -1.0 -1.0 -1.0 -1.0  \n",
       "14    1.0 -1.0 -1.0 -1.0 -1.0  \n",
       "15    1.0 -1.0 -1.0 -1.0 -1.0  \n",
       "16   -1.0 -1.0 -1.0 -1.0  1.0  \n",
       "17    1.0 -1.0 -1.0 -1.0 -1.0  \n",
       "18    1.0 -1.0 -1.0 -1.0 -1.0  \n",
       "19   -1.0 -1.0 -1.0 -1.0  1.0  \n",
       "20   -1.0 -1.0 -1.0 -1.0  1.0  \n",
       "21    1.0 -1.0 -1.0 -1.0 -1.0  \n",
       "22    1.0 -1.0 -1.0 -1.0 -1.0  \n",
       "23   -1.0 -1.0 -1.0 -1.0  1.0  \n",
       "24    1.0 -1.0 -1.0 -1.0 -1.0  \n",
       "25   -1.0 -1.0 -1.0 -1.0  1.0  \n",
       "26    1.0 -1.0 -1.0 -1.0 -1.0  \n",
       "27   -1.0 -1.0 -1.0  1.0 -1.0  \n",
       "28    1.0 -1.0 -1.0 -1.0 -1.0  \n",
       "29    1.0 -1.0 -1.0 -1.0 -1.0  \n",
       "...   ...  ...  ...  ...  ...  \n",
       "4110  1.0 -1.0 -1.0 -1.0 -1.0  \n",
       "4111  1.0 -1.0 -1.0 -1.0 -1.0  \n",
       "4112  1.0 -1.0 -1.0 -1.0 -1.0  \n",
       "4113  1.0 -1.0 -1.0 -1.0 -1.0  \n",
       "4114 -1.0 -1.0 -1.0 -1.0  1.0  \n",
       "4115  1.0 -1.0 -1.0 -1.0 -1.0  \n",
       "4116  1.0 -1.0 -1.0 -1.0 -1.0  \n",
       "4117  1.0 -1.0 -1.0 -1.0 -1.0  \n",
       "4118 -1.0 -1.0 -1.0 -1.0  1.0  \n",
       "4119 -1.0 -1.0 -1.0 -1.0  1.0  \n",
       "4120 -1.0 -1.0 -1.0 -1.0  1.0  \n",
       "4121 -1.0 -1.0 -1.0 -1.0  1.0  \n",
       "4122 -1.0 -1.0 -1.0 -1.0  1.0  \n",
       "4123 -1.0 -1.0 -1.0 -1.0  1.0  \n",
       "4124 -1.0 -1.0 -1.0 -1.0  1.0  \n",
       "4125 -1.0 -1.0 -1.0 -1.0  1.0  \n",
       "4126 -1.0 -1.0 -1.0 -1.0  1.0  \n",
       "4127 -1.0 -1.0 -1.0 -1.0  1.0  \n",
       "4128 -1.0 -1.0 -1.0 -1.0  1.0  \n",
       "4129 -1.0 -1.0 -1.0 -1.0  1.0  \n",
       "4130 -1.0 -1.0 -1.0 -1.0  1.0  \n",
       "4131  1.0 -1.0 -1.0 -1.0 -1.0  \n",
       "4132  1.0 -1.0 -1.0 -1.0 -1.0  \n",
       "4133 -1.0 -1.0 -1.0 -1.0  1.0  \n",
       "4134 -1.0 -1.0 -1.0 -1.0  1.0  \n",
       "4135 -1.0 -1.0 -1.0 -1.0  1.0  \n",
       "4136 -1.0 -1.0 -1.0 -1.0  1.0  \n",
       "4137 -1.0 -1.0 -1.0 -1.0  1.0  \n",
       "4138 -1.0 -1.0 -1.0 -1.0  1.0  \n",
       "4139 -1.0 -1.0 -1.0 -1.0  1.0  \n",
       "\n",
       "[4140 rows x 15 columns]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import neighbors\n",
    "#from sklearn import datasets\n",
    "import pickle\n",
    "\n",
    "# we will use a smaller dataset for example sake\n",
    "ofname = open('../Data/dataset_small.pkl','rb') \n",
    "(X,y) = pickle.load(ofname)\n",
    "print X.shape\n",
    "print y.size\n",
    "df = pd.DataFrame(X)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create an instance of K-nearest neighbor classifier\n",
    "knn = neighbors.KNeighborsClassifier(n_neighbors=11)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 3: Training your model\n",
    "To fit the model, we will use sklearn's object oriented interface. Firstly we create an object, which we name 'model'. We then can use the model.fit method to set the state of the object based on the training data. The data passed to the method must be in a two dimensional numpy array $\\mathbf{X}$ of shape(n_samples, n_predictors holding the feature matrix and a one-dimensinal numpy array $\\mathbf{y}$ that holds the response variable values. To view the documentaiton on this method, <a href='http://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LinearRegression.html'>visit here</a>.\n",
    "\n",
    "Once you have fit the model using the appropriate parameters passed to the fit method, the new state of the model object is stored in instances attributes with a trailing underscore '\\_' (i.e. model.coefficients_). The new state can also be accessed from different methods, where the instance will return the new state in response to a method call (i.e. get_params).\n",
    "\n",
    "Estimator objects that can generate predictions provide a model.predict method. In the case of regression, model.predict will return the predicted regression values, $\\hat{\\mathbf{y}}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Complete!\n"
     ]
    }
   ],
   "source": [
    "#Train the classifier\n",
    "knn.fit(X, y)\n",
    "\n",
    "#Compute the prediction according to the model\n",
    "y_pred = knn.predict(X)\n",
    "\n",
    "print(\"Complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 4: Test your model\n",
    "\n",
    "<p style=\"font-size: 16px\">Sklearn's estimators come with a score method that calculates the accuracy of the model based on the predicted values.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8316425120772947"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn.score(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "labels = 'Fully Covered', 'Not Fully Covered'\n",
    "sizes = df_lend['failed_loan'].value_counts()\n",
    "\n",
    "# np.where(condition, val if true, val if false)\n",
    "sizes = [np.sum(np.where(y==1,1,0)), np.sum(np.where(y==-1,1,0))]\n",
    "colors = ['gold', 'lightcoral']\n",
    "explode = (0.1, 0)\n",
    " \n",
    "# Plot\n",
    "plt.pie(sizes, explode=explode, labels=labels, colors=colors,\n",
    "        autopct='%1.1f%%', shadow=True, startangle=140)\n",
    " \n",
    "ply_ = plt.axis('equal')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=\"font-size: 16px\">This unbalanced labeling means that if we <b>always</b> predicted the loan will be fully funded, we would be correct 81.4% of the time, very very close to the accuracy of our model. This demonstrates that accuracy may not be the best metric for understanding the the predictive power of our classifier.A better matrix is the <i>confusion matrix</i>.</p>\n",
    "\n",
    "<table style='border-style : hidden'>\n",
    "    <tr>\n",
    "        <th></th>\n",
    "        <th>Positive</th>\n",
    "        <th>Negative</th>\n",
    "        <th></th>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <th>Positive</th>\n",
    "        <td>TP: True Positive, when correctly predicted positively</td>\n",
    "        <td>FP: False Positive, when incorrectly predicted positively</td>\n",
    "        <td>$\\to$Precision $\\frac{TP}{TP+FP}$</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <th>Prediction Negative</th>\n",
    "        <td>FN: False Negative, when incorrectly predicted negative</td>\n",
    "        <td>TN: True Negative, when correctly predicted negative</td>\n",
    "        <td>$\\to$Negative Predictive Value $\\frac{TN}{TN+FN}$</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <th></th>\n",
    "        <td>$$\\downarrow$$Sensitivity (Recall) $\\frac{TP}{TP+FN}$</td>\n",
    "        <td>$$\\downarrow$$Specificity $\\frac{TN}{TN+FP}$</td>\n",
    "        <th></th>\n",
    "    </tr>\n",
    "<table>\n",
    "\n",
    "<br>\n",
    "$$\\text{accuracy: }=\\frac{TP+TN}{TP+TN+FP+FN}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>FN</th>\n",
       "      <th>FP</th>\n",
       "      <th>TN</th>\n",
       "      <th>TP</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>results</th>\n",
       "      <td>7</td>\n",
       "      <td>690</td>\n",
       "      <td>73</td>\n",
       "      <td>3370</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         FN   FP  TN    TP\n",
       "results   7  690  73  3370"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix = dict()\n",
    "confusion_matrix['TP'] = np.sum(np.logical_and(y_pred==-1,y==-1))\n",
    "confusion_matrix['TN'] = np.sum(np.logical_and(y_pred==1,y==1))\n",
    "confusion_matrix['FP'] = np.sum(np.logical_and(y_pred==-1,y==1))\n",
    "confusion_matrix['FN'] = np.sum(np.logical_and(y_pred==1,y==-1))\n",
    "pd.DataFrame(data=confusion_matrix, index=['results'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=\"font-size: 16px\">Sklearn also has a method for this to make calculation easier. For a more elaborate example of how to use this, <a href='http://scikit-learn.org/stable/auto_examples/model_selection/plot_confusion_matrix.html#sphx-glr-auto-examples-model-selection-plot-confusion-matrix-py'>visit here</a>.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[3370,  690],\n",
       "       [   7,   73]], dtype=int64)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "confusion_matrix(y_pred,y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dividing data for training and testing</h3>\n",
    "<p style=\"font-size: 16px\">We have previously used full dataset for fitting the mdoek and evaluating the model, this is not good practice. It is better practice to use a subset of the data to train on and then test the accuracy of your model with a smaller subset of data that was not part of your training dataset. This is because we want to compare the <i>in-sample error rate</i> $E_{in}$ or the error on values in the training set and <i>out of sample error</i> $E_{out}$ which is the generalization error on unseen data, or our test set.</p>\n",
    "\n",
    "$$E_{in}=\\frac{1}{N}\\sum_{i=1}^{N}e(x_i, y_i)$$\n",
    "$$E_{out}=E_{xy}(e(x,y))$$\n",
    "$$\\text{ where } e(x_i, y_i)=I[h(x)=y_i]= \n",
    "\\begin{cases}\n",
    "    1     & \\quad \\text{if } h(x_i)=y\\\\\n",
    "    0 & \\quad \\text{otherwise }\n",
    "  \\end{cases}$$\n",
    "$$\\text{observe that }E_{out}\\geq E_{in}$$\n",
    "\n",
    "<p style=\"font-size: 16px\">The goal of model learning is to minimize the genearalization error. Desirable:</p>\n",
    "<li>$E_{in}\\to 0$</li>\n",
    "<li>$E_{out}\\approx E_{in}$</li>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training shape: (2898L, 15L), training targets shape: (2898L,)\n",
      "Testing shape: (1242L, 15L), testing targets shape: (1242L,)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Test</th>\n",
       "      <th>Training</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>FN</th>\n",
       "      <td>155.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FP</th>\n",
       "      <td>161.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TN</th>\n",
       "      <td>64.000000</td>\n",
       "      <td>544.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TP</th>\n",
       "      <td>862.000000</td>\n",
       "      <td>2354.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>classification_acc</th>\n",
       "      <td>0.745572</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          Test  Training\n",
       "FN                  155.000000       0.0\n",
       "FP                  161.000000       0.0\n",
       "TN                   64.000000     544.0\n",
       "TP                  862.000000    2354.0\n",
       "classification_acc    0.745572       1.0"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# train_test_split splits the data into random subsets.\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30, random_state=y.size)  \n",
    "print('Training shape: {}, training targets shape: {}'.format(X_train.shape, y_train.shape))\n",
    "print('Testing shape: {}, testing targets shape: {}'.format(X_test.shape, y_test.shape))\n",
    "\n",
    "knn = neighbors.KNeighborsClassifier(n_neighbors=1)\n",
    "knn.fit(X_train,y_train)\n",
    "\n",
    "#Check on the training set and visualize performance\n",
    "y_pred_train =knn.predict(X_train)\n",
    "y_pred_test = knn.predict(X_test)\n",
    "\n",
    "results = dict()\n",
    "train_cm = confusion_matrix(y_train, y_pred_train)\n",
    "results['Training'] = {'classification_acc': accuracy_score(y_pred_train, y_train),\n",
    "                      'TP': train_cm[0,0], 'FP': train_cm[0,1],\n",
    "                      'FN': train_cm[1,0], 'TN': train_cm[1,1]}\n",
    "\n",
    "test_cm = confusion_matrix(y_test, y_pred_test)\n",
    "results['Test'] = {'classification_acc': accuracy_score(y_pred_test, y_test),\n",
    "                      'TP': test_cm[0,0], 'FP': test_cm[0,1],\n",
    "                      'FN': test_cm[1,0], 'TN': test_cm[1,1]}\n",
    "\n",
    "pd.DataFrame(data=results)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# References\n",
    "\n",
    "1. Deep Learning, https://arxiv.org/pdf/1404.7828.pdf\n",
    "2. Pytorch, Deep Learning Python Library, https://pytorch.org\n",
    "3. Scikit-Learn, Python Library for Machine Learning, http://scikit-learn.org/stable/index.html\n",
    "4. Next Generation AI: Common Sense, https://www.youtube.com/watch?time_continue=2564&v=7ROelYvo8f0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Last updated on 10.18.18 2:11am<br>\n",
    "(C) 2018 Complex Adaptive Systems Laboratory all rights reserved._"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
