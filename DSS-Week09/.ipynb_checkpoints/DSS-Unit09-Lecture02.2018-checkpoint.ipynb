{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "<h1> Introduction to Supervised Learning through Scikit-Learn</h1>\n",
    "<h2>What is scikit-learn?</h2>\n",
    "<p style=\"font-size: 16px\">Scikit is a machine learning python library built off of packages you have recently been introduced to such as numpy, scipy and matplotlib. For more information, visit the <a href='http://scikit-learn.org/stable/index.html#'>scikit-learn homepage</a><br>\n",
    "\n",
    "<br>The library contains function in the following machine learning categories:\n",
    "<li style=\"font-size: 16px\"><a href='http://scikit-learn.org/stable/supervised_learning.html#supervised-learning'> Classification</a> </li>\n",
    "<li style=\"font-size: 16px\"><a href='http://scikit-learn.org/stable/supervised_learning.html#supervised-learning'> Regression </a></li>\n",
    "<li style=\"font-size: 16px\"><a href='http://scikit-learn.org/stable/modules/clustering.html#clustering'> Clustering </a></li>\n",
    "<li style=\"font-size: 16px\"><a href='http://scikit-learn.org/stable/modules/decomposition.html#decompositions'>Dimensionality Reduction</a></li>\n",
    "<li style=\"font-size: 16px\"><a href='http://scikit-learn.org/stable/model_selection.html#model-selection'>Model Selection</a></li>\n",
    "<li style=\"font-size: 16px\"><a href='http://scikit-learn.org/stable/modules/preprocessing.html#preprocessing'>Preprocessing </a></li>\n",
    "\n",
    "<p style=\"font-size: 16px\">Scikit-learn should be installed along with your Anaconda3 installation. However, if this is not the case, follow the installation instructions provided by scikit-learn <a href='http://scikit-learn.org/stable/install.html'>here</a><br>\n",
    "\n",
    "<br>Next, lets import some of the packages we will use and see what version you are running!</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The scikit-learn version is 0.19.1.\n",
      "The pandas version is 0.23.0\n",
      "The matplotlib version is 2.2.2\n",
      "The numpy version is 1.14.3\n"
     ]
    }
   ],
   "source": [
    "import sklearn\n",
    "print('The scikit-learn version is {}.'.format(sklearn.__version__))\n",
    "import pandas as pd\n",
    "print('The pandas version is {}'.format(pd.__version__))\n",
    "import matplotlib\n",
    "print('The matplotlib version is {}'.format(matplotlib.__version__))\n",
    "import numpy as np\n",
    "print('The numpy version is {}'.format(np.__version__))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>What is supervised learning?</h2>\n",
    "<p style=\"font-size: 16px\">Supervised learning are algorithms that learn patterns from the data using a training subset with labels to generalize to the set of all possible inputs. Examples of techniques in supervised learning:</p> \n",
    "<li style=\"font-size: 16px\"><a href='http://scikit-learn.org/stable/modules/linear_model.html#logistic-regression'>logistic regression</a></li>\n",
    "<li style=\"font-size: 16px\"><a href='http://scikit-learn.org/stable/modules/svm.html'>support vector machines</a></li>\n",
    "<li style=\"font-size: 16px\"><a href='http://scikit-learn.org/stable/modules/tree.html'>decision trees</a></li>\n",
    "<li style=\"font-size: 16px\"><a href='http://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html'>random forest</a></li>\n",
    "\n",
    "\n",
    "<p style=\"font-size: 16px\">We will focus on classification tasks in this notebook. Classification is the prediction of discrete variables i.e. YES/NO. Classification is regarded as the problem of finding $h(x): \\mathbb{R^d}\\to\\mathbb{K}$ that maps an input space in $\\mathbb{R^d}$ onto a discrete set of $k$ target outputs or classes $\\mathbb{K}=\\{1,...,k\\}$\n",
    "In contrast, regression problems involve prediction of continuous variables. </p>\n",
    "\n",
    "<p style=\"font-size: 16px\">Input data into sklearn objects are structured in numpy arrays with size [n_samples, n_features].</p>\n",
    "$$\\text{feature matrix: } \\mathbf{X} = \n",
    "\\begin{pmatrix} \n",
    "x_{11} & x_{12} & \\cdots & x_{1d} \\\\ \n",
    "x_{21} & x_{22} & \\cdots & x_{2d} \\\\\n",
    "x_{31} & x_{32} & \\cdots & x_{3d} \\\\\n",
    "\\vdots & \\vdots & \\ddots & \\vdots \\\\\n",
    "\\vdots & \\vdots & \\ddots & \\vdots \\\\\n",
    "x_{n1} & x_{n2} & \\cdots & x_{nd} \n",
    "\\end{pmatrix}\n",
    "$$\n",
    "$$ \n",
    "\\text{label vector: }\n",
    "\\mathbf{y^T} = [y_1, y_2, y_3,\\cdots, y_n]\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Case 1: Lending Club</h2>\n",
    "<p style=\"font-size: 16px\">This dataset is provided by the Lending Club, a peer-to-peer lending company offering loans funded by other people acting as hub connection borrowers and investors. The company assesses the risk of clients applying for a loan of a certain amount and whether it will be fully funded. The task is to predict unsuccessful accepted loans defined if the funded amount (funded_amnt) or the amount funded by investors (funded_amnt_inv) falls short of the request loan amount (loan_amnt).</p><br> $$\\text{binary classification task of:  }\\frac{loan-funded}{loan}\\geq0.95$$ \n",
    "\n",
    "<br><a href='https://www.lendingclub.com/info/download-data.action'>Download data here for years 2007-2011</a></p>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table>\n",
    "    <tr>\n",
    "        <th>Column</th>\n",
    "        <th>Description</th>\n",
    "    </tr>\n",
    "   <tr>\n",
    "        <td>annual_inc</td>\n",
    "        <td>The annual income provided by the borrower during registration.</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>delinq_2yrs</td>\n",
    "        <td> The number of 30+ days past-due incidences of delinquency in the borrower's credit file for the past 2 years\n",
    "</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>dti</td>\n",
    "        <td> A ratio calculated using the borrower’s total monthly debt payments on the total debt obligations, excluding mortgage and the requested LC loan, divided by the borrower’s self-reported monthly income.\n",
    "</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>earliest_cr_line</td>\n",
    "        <td> The month the borrower's earliest reported credit line was opened\n",
    "</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>emp_length</td>\n",
    "        <td> Employment length in years. Possible values are between 0 and 10 where 0 means less than one year and 10 means ten or more years.\n",
    "</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>home_ownership</td>\n",
    "        <td> The home ownership status provided by the borrower during registration. Our values are: RENT, OWN, MORTGAGE, OTHER.\n",
    "</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>installment</td>\n",
    "        <td> The monthly payment owed by the borrower if the loan originates.\n",
    "</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>int_rate</td>\n",
    "        <td> Interest Rate on the loan\n",
    "</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>is_inc_v</td>\n",
    "        <td> Indicates if income was verified by LC, not verified, or if the income source was verified\n",
    "</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>last_fico_range_high</td>\n",
    "        <td> The last upper boundary of range the borrower’s FICO belongs to pulled.\n",
    "</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>last_fico_range_low</td>\n",
    "        <td> The last lower boundary of range the borrower’s FICO belongs to pulled.\n",
    "</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>fico_range_high</td>\n",
    "        <td> The upper boundary of range the borrower’s FICO belongs to.\n",
    "</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>fico_range_low</td>\n",
    "        <td> The lower boundary of range the borrower’s FICO belongs to.\n",
    "</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>mths_since_last_delinq</td>\n",
    "        <td> The number of months since the borrower's last delinquency.\n",
    "</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>mths_since_last_major_derog</td>\n",
    "        <td> Months since most recent 90-day or worse rating\n",
    "</td>\n",
    "    </tr>\n",
    "     <tr>\n",
    "        <td>open_acc</td>\n",
    "        <td> The number of open credit lines in the borrower's credit file.\n",
    "</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>term</td>\n",
    "        <td> The number of payments on the loan. Values are in months and can be either 36 or 60.\n",
    "</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>total_acc</td>\n",
    "        <td> The total number of credit lines currently in the borrower's credit file\n",
    "</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>loan_amnt</td>\n",
    "        <td> The listed amount of the loan applied for by the borrower. If at some point in time, the credit department reduces the loan amount, then it will be reflected in this value.</td>\n",
    "    </tr>\n",
    "\n",
    "\n",
    "</table>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "IOError",
     "evalue": "File files_ch05/LoanStats3a.csv does not exist",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m\u001b[0m",
      "\u001b[1;31mIOError\u001b[0mTraceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-8eeed97280cd>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mkeep_cols\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;34m'loan_amnt'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'funded_amnt'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'funded_amnt_inv'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'term'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'int_rate'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'installment'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'emp_length'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'home_ownership'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'annual_inc'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'dti'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'delinq_2yrs'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'mths_since_last_delinq'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'total_acc'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mdf_lend\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'files_ch05/LoanStats3a.csv'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mskiprows\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlow_memory\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mdf_lend\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdf_lend\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mkeep_cols\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf_lend\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf_lend\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\ra407452\\AppData\\Local\\Continuum\\anaconda2\\lib\\site-packages\\pandas\\io\\parsers.pyc\u001b[0m in \u001b[0;36mparser_f\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, escapechar, comment, encoding, dialect, tupleize_cols, error_bad_lines, warn_bad_lines, skipfooter, doublequote, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[0;32m    676\u001b[0m                     skip_blank_lines=skip_blank_lines)\n\u001b[0;32m    677\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 678\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    679\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    680\u001b[0m     \u001b[0mparser_f\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\ra407452\\AppData\\Local\\Continuum\\anaconda2\\lib\\site-packages\\pandas\\io\\parsers.pyc\u001b[0m in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    438\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    439\u001b[0m     \u001b[1;31m# Create the parser.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 440\u001b[1;33m     \u001b[0mparser\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    441\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    442\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\ra407452\\AppData\\Local\\Continuum\\anaconda2\\lib\\site-packages\\pandas\\io\\parsers.pyc\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m    785\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'has_index_names'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'has_index_names'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    786\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 787\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    788\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    789\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\ra407452\\AppData\\Local\\Continuum\\anaconda2\\lib\\site-packages\\pandas\\io\\parsers.pyc\u001b[0m in \u001b[0;36m_make_engine\u001b[1;34m(self, engine)\u001b[0m\n\u001b[0;32m   1012\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'c'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1013\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'c'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1014\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1015\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1016\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'python'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\ra407452\\AppData\\Local\\Continuum\\anaconda2\\lib\\site-packages\\pandas\\io\\parsers.pyc\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, src, **kwds)\u001b[0m\n\u001b[0;32m   1706\u001b[0m         \u001b[0mkwds\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'usecols'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0musecols\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1707\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1708\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mparsers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1709\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1710\u001b[0m         \u001b[0mpassed_names\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnames\u001b[0m \u001b[1;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._setup_parser_source\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mIOError\u001b[0m: File files_ch05/LoanStats3a.csv does not exist"
     ]
    }
   ],
   "source": [
    "keep_cols = ['loan_amnt', 'funded_amnt', 'funded_amnt_inv', 'term', 'int_rate', 'installment', 'emp_length', 'home_ownership', 'annual_inc', 'dti', 'delinq_2yrs', 'mths_since_last_delinq', 'total_acc']\n",
    "df_lend = pd.read_csv('files_ch05/LoanStats3a.csv', skiprows=1, low_memory=False)\n",
    "df_lend = df_lend[keep_cols]\n",
    "print(df_lend.shape)\n",
    "print(df_lend.columns.tolist())\n",
    "df_lend.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=\"font-size: 16px\">We will encode our binary target variable using the logic described earlier and visualize the results: $$\\frac{loan-funded}{loan}\\geq0.95$$  </p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loan = df_lend['loan_amnt'].values\n",
    "funded = df_lend['funded_amnt_inv'].values\n",
    "targets = np.abs(loan-funded)/loan\n",
    "\n",
    "df_lend['targets'] = targets\n",
    "y = [-1 if t >= .95 else 1 for t in targets]\n",
    "df_lend['failed_loan'] = y\n",
    "df_lend['failed_loan'].value_counts()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline \n",
    "labels = 'Fully Covered', 'Not Fully Covered'\n",
    "sizes = df_lend['failed_loan'].value_counts()\n",
    "sizes = [sizes[1], sizes[-1] ]\n",
    "colors = ['gold', 'lightcoral']\n",
    " \n",
    "# Plot\n",
    "plt.pie(sizes, labels=labels, colors=colors,\n",
    "        autopct='%1.1f%%', shadow=True, startangle=140)\n",
    " \n",
    "plot_ = plt.axis('equal')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=\"font-size: 16px\">Note that there is a significant disporportion of positive labels to negative ones, making the dataset unbalanced. This can have drastic consequences for a classifier.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "loan = df_lend['loan_amnt'].values\n",
    "funded = df_lend['funded_amnt_inv'].values\n",
    "targets = np.abs(loan-funded)/loan\n",
    "\n",
    "df_lend['targets'] = targets\n",
    "wrk_records = np.where(~np.isnan(targets))\n",
    "y = targets[wrk_records]>=0.05\n",
    "plt.hist(targets[wrk_records],bins=30)\n",
    "\n",
    "print('Larger deviation: {}'.format(np.sum(y)))\n",
    "print('Total: {}'.format(np.sum(1-y)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=\"font-size: 16px\">Now for a quick introduction in the functionality of sklearn. We will begin with the k-nearest neighbor clustering algorithm. For more details, see pages 462-470 in Python for Data Science Handbook VanderPlas, Jake)</p>\n",
    "<h2>What is K-Nearest Neighbor?</h2>\n",
    "<p style=\"font-size: 16px\">This algorithm, when used for classification, uses the neighboring values of a particular input value to make a prediction. The input is assigned to the class most common among its $k$ nearest neighbors where $k\\in\\mathbf{R}$. The parameter $k$ is defined in the beginning as a hyperparameter, or a configuration that is prior to the model fit and is not estimated from the data but can be tuned to be more beneficial to the fitting of the model on the data. Determining the distance between the input value and other values is commonly done by Euclidean distance for continuous variables or Hamming distance for discrete variables. We will not go into too much detail here, but we will use this algorithm as a starting example on sklearn. For more information on sklearn's package, see the <a href='http://scikit-learn.org/stable/modules/neighbors.html#neighbors'>sklearn.neighbors documentation.</a>\n",
    "<br><br>\n",
    "One thing to note is this algorithm is computation heavy. This is because it must hold all other values in memory in order to measure the closest $k$ values to the input value.</p>\n",
    "\n",
    "<h3>Training a Model with sklearn 5.3</h3>\n",
    "<p style=\"font-size: 16px\">To fit the model, we will use sklearn's object oriented interface. Firstly we create an object, which we name 'model'. We then can use the model.fit method to set the state of the object based on the training data. The data passed to the method must be in a two dimensional numpy array $\\mathbf{X}$ of shape(n_samples, n_predictors holding the feature matrix and a one-dimensinal numpy array $\\mathbf{y}$ that holds the response variable values. To view the documentaiton on this method, <a href='http://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LinearRegression.html'>visit here</a>.</p>\n",
    "\n",
    "<p style=\"font-size: 16px\">Once you have fit the model using the appropriate parameters passed to the fit method, the new state of the model object is stored in instances attributes with a trailing underscore '\\_' (i.e. model.coefficients_). The new state can also be accessed from different methods, where the instance will return the new state in response to a method call (i.e. get_params).</p>\n",
    "\n",
    "<p style=\"font-size: 16px\">Estimator objects that can generate predictions provide a model.predict method. In the case of regression, model.predict will return the predicted regression values, $\\hat{\\mathbf{y}}$.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import neighbors\n",
    "from sklearn import datasets\n",
    "import pickle\n",
    "\n",
    "# we will use a smaller dataset for example sake\n",
    "ofname = open('files_ch05/dataset_small.pkl','rb') \n",
    "(X,y) = pickle.load(ofname, encoding='bytes')\n",
    "\n",
    "#Create an instance of K-nearest neighbor classifier\n",
    "knn = neighbors.KNeighborsClassifier(n_neighbors=11)\n",
    "\n",
    "#Train the classifier\n",
    "knn.fit(X, y)\n",
    "\n",
    "#Compute the prediction according to the model\n",
    "y_pred = knn.predict(X)\n",
    "\n",
    "print(\"Complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=\"font-size: 16px\">Sklearn's estimators come with a score method that calculates the accuracy of the model based on the predicted values.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn.score(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = 'Fully Covered', 'Not Fully Covered'\n",
    "sizes = df_lend['failed_loan'].value_counts()\n",
    "\n",
    "# np.where(condition, val if true, val if false)\n",
    "sizes = [np.sum(np.where(y==1,1,0)), np.sum(np.where(y==-1,1,0))]\n",
    "colors = ['gold', 'lightcoral']\n",
    "explode = (0.1, 0)\n",
    " \n",
    "# Plot\n",
    "plt.pie(sizes, explode=explode, labels=labels, colors=colors,\n",
    "        autopct='%1.1f%%', shadow=True, startangle=140)\n",
    " \n",
    "ply_ = plt.axis('equal')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=\"font-size: 16px\">This unbalanced labeling means that if we <b>always</b> predicted the loan will be fully funded, we would be correct 81.4% of the time, very very close to the accuracy of our model. This demonstrates that accuracy may not be the best metric for understanding the the predictive power of our classifier.A better matrix is the <i>confusion matrix</i>.</p>\n",
    "\n",
    "<table style='border-style : hidden'>\n",
    "    <tr>\n",
    "        <th></th>\n",
    "        <th>Positive</th>\n",
    "        <th>Negative</th>\n",
    "        <th></th>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <th>Positive</th>\n",
    "        <td>TP: True Positive, when correctly predicted positively</td>\n",
    "        <td>FP: False Positive, when incorrectly predicted positively</td>\n",
    "        <td>$\\to$Precision $\\frac{TP}{TP+FP}$</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <th>Prediction Negative</th>\n",
    "        <td>FN: False Negative, when incorrectly predicted negative</td>\n",
    "        <td>TN: True Negative, when correctly predicted negative</td>\n",
    "        <td>$\\to$Negative Predictive Value $\\frac{TN}{TN+FN}$</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <th></th>\n",
    "        <td>$$\\downarrow$$Sensitivity (Recall) $\\frac{TP}{TP+FN}$</td>\n",
    "        <td>$$\\downarrow$$Specificity $\\frac{TN}{TN+FP}$</td>\n",
    "        <th></th>\n",
    "    </tr>\n",
    "<table>\n",
    "\n",
    "<br>\n",
    "$$\\text{accuracy: }=\\frac{TP+TN}{TP+TN+FP+FN}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion_matrix = dict()\n",
    "confusion_matrix['TP'] = np.sum(np.logical_and(y_pred==-1,y==-1))\n",
    "confusion_matrix['TN'] = np.sum(np.logical_and(y_pred==1,y==1))\n",
    "confusion_matrix['FP'] = np.sum(np.logical_and(y_pred==-1,y==1))\n",
    "confusion_matrix['FN'] = np.sum(np.logical_and(y_pred==1,y==-1))\n",
    "pd.DataFrame(data=confusion_matrix, index=['results'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=\"font-size: 16px\">Sklearn also has a method for this to make calculation easier. For a more elaborate example of how to use this, <a href='http://scikit-learn.org/stable/auto_examples/model_selection/plot_confusion_matrix.html#sphx-glr-auto-examples-model-selection-plot-confusion-matrix-py'>visit here</a>.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "confusion_matrix(y_pred,y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Training and Testing Subsets 5.6</h3>\n",
    "<p style=\"font-size: 16px\">We have previously used full dataset for fitting the mdoek and evaluating the model, this is not good practice. It is better practice to use a subset of the data to train on and then test the accuracy of your model with a smaller subset of data that was not part of your training dataset. This is because we want to compare the <i>in-sample error rate</i> $E_{in}$ or the error on values in the training set and <i>out of sample error</i> $E_{out}$ which is the generalization error on unseen data, or our test set.</p>\n",
    "\n",
    "$$E_{in}=\\frac{1}{N}\\sum_{i=1}^{N}e(x_i, y_i)$$\n",
    "$$E_{out}=E_{xy}(e(x,y))$$\n",
    "$$\\text{ where } e(x_i, y_i)=I[h(x)=y_i]= \n",
    "\\begin{cases}\n",
    "    1     & \\quad \\text{if } h(x_i)=y\\\\\n",
    "    0 & \\quad \\text{otherwise }\n",
    "  \\end{cases}$$\n",
    "$$\\text{observe that }E_{out}\\geq E_{in}$$\n",
    "\n",
    "<p style=\"font-size: 16px\">The goal of model learning is to minimize the genearalization error. Desirable:</p>\n",
    "<li>$E_{in}\\to 0$</li>\n",
    "<li>$E_{out}\\approx E_{in}$</li>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# train_test_split splits the data into random subsets.\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30, random_state=y.size)  \n",
    "print('Training shape: {}, training targets shape: {}'.format(X_train.shape, y_train.shape))\n",
    "print('Testing shape: {}, testing targets shape: {}'.format(X_test.shape, y_test.shape))\n",
    "\n",
    "knn = neighbors.KNeighborsClassifier(n_neighbors=1)\n",
    "knn.fit(X_train,y_train)\n",
    "\n",
    "#Check on the training set and visualize performance\n",
    "y_pred_train =knn.predict(X_train)\n",
    "y_pred_test = knn.predict(X_test)\n",
    "\n",
    "results = dict()\n",
    "train_cm = confusion_matrix(y_train, y_pred_train)\n",
    "results['Training'] = {'classification_acc': accuracy_score(y_pred_train, y_train),\n",
    "                      'TP': train_cm[0,0], 'FP': train_cm[0,1],\n",
    "                      'FN': train_cm[1,0], 'TN': train_cm[1,1]}\n",
    "\n",
    "test_cm = confusion_matrix(y_test, y_pred_test)\n",
    "results['Test'] = {'classification_acc': accuracy_score(y_pred_test, y_test),\n",
    "                      'TP': test_cm[0,0], 'FP': test_cm[0,1],\n",
    "                      'FN': test_cm[1,0], 'TN': test_cm[1,1]}\n",
    "\n",
    "pd.DataFrame(data=results)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
